{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8WZXl8z-1VC"
   },
   "source": [
    "# **Phishing Website Detection Feature Extraction**\n",
    "\n",
    "*Final project of AI & Cybersecurity Course*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUwXaC2JiIMF"
   },
   "source": [
    "# **1. Objective:**\n",
    "A phishing website is a common social engineering method that mimics trustful uniform resource locators (URLs) and webpages. The objective of this notebook is to collect data & extract the selctive features form the URLs.\n",
    "\n",
    "*This project is worked on Google Collaboratory.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkIGg-nGiqEO"
   },
   "source": [
    "# **2. Collecting the Data:**\n",
    "For this project, we need a bunch of urls of type legitimate (0) and phishing (1). \n",
    "\n",
    "The collection of phishing urls is rather easy because of the opensource service called PhishTank. This service provide a set of phishing URLs in multiple formats like csv, json etc. that gets updated hourly. To download the data: https://www.phishtank.com/developer_info.php\n",
    "\n",
    "For the legitimate URLs, I found a source that has a collection of benign, spam, phishing, malware & defacement URLs. The source of the dataset is University of New Brunswick, https://www.unb.ca/cic/datasets/url-2016.html. The number of legitimate URLs in this collection are 35,300. The URL collection is downloaded & from that, *'Benign_list_big_final.csv'* is the file of our interest. This file is then uploaded to the Colab for the feature extraction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRyCQJnSmACu"
   },
   "source": [
    "## **2.1. Phishing URLs:**\n",
    "\n",
    "The phishing URLs are collected from the PhishTank from the link provided. The csv file of phishing URLs is obtained by using wget command. After downlaoding the dataset, it is loaded into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PH13wfswmyDv"
   },
   "outputs": [],
   "source": [
    "#importing required packages for this module\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paesHH9rnX8r"
   },
   "source": [
    "The above command downlaods the file of phishing URLs, *online-valid.csv* and stores in the */content/* folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "GaGVL9gYKXma",
    "outputId": "fad0a947-4996-44bf-d46f-89abc4306e62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phish_id</th>\n",
       "      <th>url</th>\n",
       "      <th>phish_detail_url</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>verified</th>\n",
       "      <th>verification_time</th>\n",
       "      <th>online</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6557033</td>\n",
       "      <td>http://u1047531.cp.regruhosting.ru/acces-inges...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-05-09T22:01:43+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-05-09T22:03:07+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6557032</td>\n",
       "      <td>http://hoysalacreations.com/wp-content/plugins...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-05-09T22:01:37+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-05-09T22:03:07+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6557011</td>\n",
       "      <td>http://www.accsystemprblemhelp.site/checkpoint...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-05-09T21:54:31+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-05-09T21:55:38+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6557010</td>\n",
       "      <td>http://www.accsystemprblemhelp.site/login_atte...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-05-09T21:53:48+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-05-09T21:54:34+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6557009</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/so...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-05-09T21:49:27+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-05-09T21:51:24+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phish_id                                                url  \\\n",
       "0   6557033  http://u1047531.cp.regruhosting.ru/acces-inges...   \n",
       "1   6557032  http://hoysalacreations.com/wp-content/plugins...   \n",
       "2   6557011  http://www.accsystemprblemhelp.site/checkpoint...   \n",
       "3   6557010  http://www.accsystemprblemhelp.site/login_atte...   \n",
       "4   6557009  https://firebasestorage.googleapis.com/v0/b/so...   \n",
       "\n",
       "                                    phish_detail_url  \\\n",
       "0  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "1  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "2  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "3  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "4  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "\n",
       "             submission_time verified          verification_time online  \\\n",
       "0  2020-05-09T22:01:43+00:00      yes  2020-05-09T22:03:07+00:00    yes   \n",
       "1  2020-05-09T22:01:37+00:00      yes  2020-05-09T22:03:07+00:00    yes   \n",
       "2  2020-05-09T21:54:31+00:00      yes  2020-05-09T21:55:38+00:00    yes   \n",
       "3  2020-05-09T21:53:48+00:00      yes  2020-05-09T21:54:34+00:00    yes   \n",
       "4  2020-05-09T21:49:27+00:00      yes  2020-05-09T21:51:24+00:00    yes   \n",
       "\n",
       "      target  \n",
       "0      Other  \n",
       "1      Other  \n",
       "2   Facebook  \n",
       "3   Facebook  \n",
       "4  Microsoft  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the phishing URLs data to dataframe\n",
    "data0 = pd.read_csv(\"dataFiles/online-valid.csv\")\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mAZAvSe2n1oT",
    "outputId": "da2fbbb6-871f-4070-df86-cc9a135ac37a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14858, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBFvH8h0oFkO"
   },
   "source": [
    "So, the data has thousands of phishing URLs. But the problem here is, this data gets updated hourly. Without getting into the risk of data imbalance, I am considering a margin value of 10,000 phishing URLs & 5000 legitimate URLs. \n",
    "\n",
    "Thereby, picking up 5000 samples from the above dataframe randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "9CTCI_EgERPM",
    "outputId": "cb74e74c-5591-4523-e077-bbf13ef89245"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phish_id</th>\n",
       "      <th>url</th>\n",
       "      <th>phish_detail_url</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>verified</th>\n",
       "      <th>verification_time</th>\n",
       "      <th>online</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6514946</td>\n",
       "      <td>http://confirmprofileaccount.com/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-04-19T11:06:55+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-04-19T13:42:41+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4927651</td>\n",
       "      <td>http://www.marreme.com/MasterAdmin/04mop.html</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2017-04-04T19:35:54+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2017-05-03T23:00:42+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5116976</td>\n",
       "      <td>http://modsecpaststudents.com/review/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2017-07-25T18:48:30+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2017-07-28T16:01:36+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6356131</td>\n",
       "      <td>https://docs.google.com/forms/d/e/1FAIpQLScL6L...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-01-13T20:13:37+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-01-17T01:55:38+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6535965</td>\n",
       "      <td>https://oportunidadedasemana.com/americanas//?...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2020-04-29T00:01:03+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2020-05-01T10:55:35+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phish_id                                                url  \\\n",
       "0   6514946                  http://confirmprofileaccount.com/   \n",
       "1   4927651      http://www.marreme.com/MasterAdmin/04mop.html   \n",
       "2   5116976              http://modsecpaststudents.com/review/   \n",
       "3   6356131  https://docs.google.com/forms/d/e/1FAIpQLScL6L...   \n",
       "4   6535965  https://oportunidadedasemana.com/americanas//?...   \n",
       "\n",
       "                                    phish_detail_url  \\\n",
       "0  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "1  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "2  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "3  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "4  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "\n",
       "             submission_time verified          verification_time online target  \n",
       "0  2020-04-19T11:06:55+00:00      yes  2020-04-19T13:42:41+00:00    yes  Other  \n",
       "1  2017-04-04T19:35:54+00:00      yes  2017-05-03T23:00:42+00:00    yes  Other  \n",
       "2  2017-07-25T18:48:30+00:00      yes  2017-07-28T16:01:36+00:00    yes  Other  \n",
       "3  2020-01-13T20:13:37+00:00      yes  2020-01-17T01:55:38+00:00    yes  Other  \n",
       "4  2020-04-29T00:01:03+00:00      yes  2020-05-01T10:55:35+00:00    yes  Other  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collecting 5,000 Phishing URLs randomly\n",
    "phishurl = data0.sample(n = 5000, random_state = 12).copy()\n",
    "phishurl = phishurl.reset_index(drop=True)\n",
    "phishurl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-FOfv0bspc8N",
    "outputId": "48e76e11-37d7-4ba1-e04a-c2fa661e9219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishurl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sb4afcd5pges"
   },
   "source": [
    "As of now we collected 5000 phishing URLs. Now, we need to collect the legitimate URLs.\n",
    "\n",
    "## **2.2. Legitimate URLs:**\n",
    "\n",
    "From the uploaded *Benign_list_big_final.csv* file, the URLs are loaded into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "0wkw4wGAsIbT",
    "outputId": "4395a2bd-dd8b-49ea-fb1e-36cf0b67e75f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://1337x.to/torrent/1110018/Blackhat-2015-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://1337x.to/torrent/1122940/Blackhat-2015-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://1337x.to/torrent/1124395/Fast-and-Furio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://1337x.to/torrent/1145504/Avengers-Age-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://1337x.to/torrent/1160078/Avengers-age-o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  http://1337x.to/torrent/1110018/Blackhat-2015-...\n",
       "1  http://1337x.to/torrent/1122940/Blackhat-2015-...\n",
       "2  http://1337x.to/torrent/1124395/Fast-and-Furio...\n",
       "3  http://1337x.to/torrent/1145504/Avengers-Age-o...\n",
       "4  http://1337x.to/torrent/1160078/Avengers-age-o..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading legitimate files \n",
    "data1 = pd.read_csv(\"dataFiles/Benign_list_big_final.csv\")\n",
    "data1.columns = ['URLs']\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdvE4YfWtCJr"
   },
   "source": [
    "As stated above, 5000 legitimate URLs are randomaly picked from the above dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "EQRtf9Ybs5sv",
    "outputId": "227e262b-1483-4549-8bdf-49da2f321b06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://graphicriver.net/search?date=this-month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://ecnavi.jp/redirect/?url=http://www.cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://hubpages.com/signin?explain=follow+Hub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://extratorrent.cc/torrent/4190536/AOMEI+B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://icicibank.com/Personal-Banking/offers/o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  http://graphicriver.net/search?date=this-month...\n",
       "1  http://ecnavi.jp/redirect/?url=http://www.cros...\n",
       "2  https://hubpages.com/signin?explain=follow+Hub...\n",
       "3  http://extratorrent.cc/torrent/4190536/AOMEI+B...\n",
       "4  http://icicibank.com/Personal-Banking/offers/o..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collecting 5,000 Legitimate URLs randomly\n",
    "legiurl = data1.sample(n = 5000, random_state = 12).copy()\n",
    "legiurl = legiurl.reset_index(drop=True)\n",
    "legiurl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QrpSRXzDuKwW",
    "outputId": "8b8e5220-be59-4893-9dd5-3ffc381d2b1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legiurl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbzZbsWIEV6J"
   },
   "source": [
    "# **3. Feature Extraction:**\n",
    "\n",
    "In this step, features are extracted from the URLs dataset.\n",
    "\n",
    "The extracted features are categorized into\n",
    "\n",
    "\n",
    "1.   Address Bar based Features\n",
    "2.   Domain based Features\n",
    "3.   HTML & Javascript based Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vABNo39RQljI"
   },
   "source": [
    "### **3.1. Address Bar Based Features:**\n",
    "\n",
    "Many features can be extracted that can be consided as address bar base features. Out of them, below mentioned were considered for this project.\n",
    "\n",
    "\n",
    "*   Domain of URL\n",
    "*   IP Address in URL\n",
    "*   \"@\" Symbol in URL\n",
    "*   Length of URL\n",
    "*   Depth of URL\n",
    "*   Redirection \"//\" in URL\n",
    "*   \"http/https\" in Domain name\n",
    "*   Using URL Shortening Services “TinyURL”\n",
    "*   Prefix or Suffix \"-\" in Domain\n",
    "\n",
    "Each of these features are explained and the coded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rk4HFWsEKXpS"
   },
   "outputs": [],
   "source": [
    "# importing required packages for this section\n",
    "from urllib.parse import urlparse,urlencode\n",
    "import ipaddress\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xd-UZd3c60-a"
   },
   "source": [
    "#### **3.1.1. Domain of the URL**\n",
    "Here, we are just extracting the domain present in the URL. This feature doesn't have much significance in the training. May even be dropped while training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0QorYenhaOD"
   },
   "outputs": [],
   "source": [
    "# 1.Domain of the URL (Domain) \n",
    "def getDomain(url):  \n",
    "  domain = urlparse(url).netloc\n",
    "  if re.match(r\"^www.\",domain):\n",
    "\t       domain = domain.replace(\"www.\",\"\")\n",
    "  return domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1EPO6HJ87Pdv"
   },
   "source": [
    "#### **3.1.2. IP Address in the URL**\n",
    "\n",
    "Checks for the presence of IP address in the URL. URLs may have IP address instead of domain name. If an IP address is used as an alternative of the domain name in the URL, we can be sure that someone is trying to steal personal information with this URL.\n",
    "\n",
    "If the domain part of URL has IP address, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SX-4mbq27QBj"
   },
   "outputs": [],
   "source": [
    "# 2.Checks for IP address in URL (Have_IP)\n",
    "def havingIP(url):\n",
    "  try:\n",
    "    ipaddress.ip_address(url)\n",
    "    ip = 1\n",
    "  except:\n",
    "    ip = 0\n",
    "  return ip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vcy-zay47S-q"
   },
   "source": [
    "#### **3.1.3. \"@\" Symbol in URL**\n",
    "\n",
    "Checks for the presence of '@' symbol in the URL. Using “@” symbol in the URL leads the browser to ignore everything preceding the “@” symbol and the real address often follows the “@” symbol. \n",
    "\n",
    "If the URL has '@' symbol, the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZQZi3K17TcR"
   },
   "outputs": [],
   "source": [
    "# 3.Checks the presence of @ in URL (Have_At)\n",
    "def haveAtSign(url):\n",
    "  if \"@\" in url:\n",
    "    at = 1    \n",
    "  else:\n",
    "    at = 0    \n",
    "  return at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhFeCv2N9KLU"
   },
   "source": [
    "#### **3.1.4. Length of URL**\n",
    "\n",
    "Computes the length of the URL. Phishers can use long URL to hide the doubtful part in the address bar. In this project, if the length of the URL is greater than or equal 54 characters then the URL classified as phishing otherwise legitimate.\n",
    "\n",
    "If the length of URL >= 54 , the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnQazil39Kra"
   },
   "outputs": [],
   "source": [
    "# 4.Finding the length of URL and categorizing (URL_Length)\n",
    "def getLength(url):\n",
    "  if len(url) < 54:\n",
    "    length = 0            \n",
    "  else:\n",
    "    length = 1            \n",
    "  return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ICyOWg59LHt"
   },
   "source": [
    "#### **3.1.5. Depth of URL**\n",
    "\n",
    "Computes the depth of the URL. This feature calculates the number of sub pages in the given url based on the '/'.\n",
    "\n",
    "The value of feature is a numerical based on the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yILgNFf_9L3X"
   },
   "outputs": [],
   "source": [
    "# 5.Gives number of '/' in URL (URL_Depth)\n",
    "def getDepth(url):\n",
    "  s = urlparse(url).path.split('/')\n",
    "  depth = 0\n",
    "  for j in range(len(s)):\n",
    "    if len(s[j]) != 0:\n",
    "      depth = depth+1\n",
    "  return depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5-eL0bBBRdx"
   },
   "source": [
    "#### **3.1.6. Redirection \"//\" in URL**\n",
    "\n",
    "Checks the presence of \"//\" in the URL. The existence of “//” within the URL path means that the user will be redirected to another website. The location of the “//” in URL is computed. We find that if the URL starts with “HTTP”, that means the “//” should appear in the sixth position. However, if the URL employs “HTTPS” then the “//” should appear in seventh position.\n",
    "\n",
    "If the \"//\" is anywhere in the URL apart from after the protocal, thee value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIJEiq51BSy0"
   },
   "outputs": [],
   "source": [
    "# 6.Checking for redirection '//' in the url (Redirection)\n",
    "def redirection(url):\n",
    "  pos = url.rfind('//')\n",
    "  if pos > 6:\n",
    "    if pos > 7:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHWQDIrtBa7n"
   },
   "source": [
    "#### **3.1.7. \"http/https\" in Domain name**\n",
    "\n",
    "Checks for the presence of \"http/https\" in the domain part of the URL. The phishers may add the “HTTPS” token to the domain part of a URL in order to trick users.\n",
    "\n",
    "If the URL has \"http/https\" in the domain part, the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2vW23O1BbWl"
   },
   "outputs": [],
   "source": [
    "# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rKL4jpeaPIvA"
   },
   "source": [
    "#### **3.1.8. Using URL Shortening Services “TinyURL”**\n",
    "\n",
    "URL shortening is a method on the “World Wide Web” in which a URL may be made considerably smaller in length and still lead to the required webpage. This is accomplished by means of an “HTTP Redirect” on a domain name that is short, which links to the webpage that has a long URL. \n",
    "\n",
    "If the URL is using Shortening Services, the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdC9pUdTAVRU"
   },
   "outputs": [],
   "source": [
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUkU9UbbnKpY"
   },
   "outputs": [],
   "source": [
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HS-BuQJzPkaZ"
   },
   "source": [
    "#### **3.1.9. Prefix or Suffix \"-\" in Domain**\n",
    "\n",
    "Checking the presence of '-' in the domain part of URL. The dash symbol is rarely used in legitimate URLs. Phishers tend to add prefixes or suffixes separated by (-) to the domain name so that users feel that they are dealing with a legitimate webpage. \n",
    "\n",
    "If the URL has '-' symbol in the domain part of the URL, the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLyjiIUgPjuw"
   },
   "outputs": [],
   "source": [
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zO485F_BPk-k"
   },
   "source": [
    "### **3.2. Domain Based Features:**\n",
    "\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "\n",
    "*   DNS Record\n",
    "*   Website Traffic \n",
    "*   Age of Domain\n",
    "*   End Period of Domain\n",
    "\n",
    "Each of these features are explained and the coded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "NbkEYJ_JOVa7",
    "outputId": "f08b25f8-3852-432c-e141-8eb57ff916d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-whois in ./myenv/lib/python3.12/site-packages (0.9.5)\n",
      "Requirement already satisfied: python-dateutil in ./myenv/lib/python3.12/site-packages (from python-whois) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil->python-whois) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esZ7FcvlOMZu"
   },
   "outputs": [],
   "source": [
    "# importing required packages for this section\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import whois\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ExXkkXYZWWZ"
   },
   "source": [
    "#### **3.2.1. DNS Record**\n",
    "\n",
    "For phishing websites, either the claimed identity is not recognized by the WHOIS database or no records founded for the hostname. \n",
    "If the DNS record is empty or not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8O5D1jH0IDgf"
   },
   "outputs": [],
   "source": [
    "# 11.DNS Record availability (DNS_Record)\n",
    "# obtained in the featureExtraction function itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5DKTVPMZ1Yk"
   },
   "source": [
    "#### **3.2.2. Web Traffic**\n",
    "\n",
    "This feature measures the popularity of the website by determining the number of visitors and the number of pages they visit. However, since phishing websites live for a short period of time, they may not be recognized by the Alexa database (Alexa the Web Information Company., 1996). By reviewing our dataset, we find that in worst scenarios, legitimate websites ranked among the top 100,000. Furthermore, if the domain has no traffic or is not recognized by the Alexa database, it is classified as “Phishing”.\n",
    "\n",
    "If the rank of the domain < 100000, the vlaue of this feature is 1 (phishing) else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./myenv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./myenv/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: urllib3 in ./myenv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: dnspython in ./myenv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./myenv/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests beautifulsoup4 urllib3 dnspython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mtwQiRotZ2GD"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import socket\n",
    "import dns.resolver\n",
    "\n",
    "def web_traffic(url):\n",
    "    \"\"\"\n",
    "    Check if a website likely has significant traffic (returns 1) or not (returns 0).\n",
    "    Mimics the behavior of the original Alexa rank function with a binary output.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean URL\n",
    "        url = urllib.parse.quote(url)\n",
    "        \n",
    "        # Extract domain\n",
    "        domain = urllib.parse.urlparse(url).netloc\n",
    "        if not domain:\n",
    "            domain = url.split('/')[0]\n",
    "        \n",
    "        # Quick checks that suggest a high-traffic site\n",
    "        signals = 0\n",
    "        \n",
    "        # 1. Check if domain resolves and website responds\n",
    "        try:\n",
    "            response = requests.get(f\"http://{domain}\", \n",
    "                                  timeout=3,\n",
    "                                  headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            if response.status_code == 200:\n",
    "                signals += 1\n",
    "                \n",
    "                # Check for common features of established sites\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                if soup.find('meta', attrs={'name': 'description'}):\n",
    "                    signals += 1\n",
    "                if soup.find('sitemap.xml') or soup.find('robots.txt'):\n",
    "                    signals += 1\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # 2. Check for multiple DNS records (common for larger sites)\n",
    "        try:\n",
    "            answers = dns.resolver.resolve(domain, 'A')\n",
    "            if len(answers) > 1:\n",
    "                signals += 1\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Return 1 if we see enough signals of an established site\n",
    "        if signals >= 2:\n",
    "            return 1\n",
    "            \n",
    "        return 0\n",
    "        \n",
    "    except Exception:\n",
    "        return 1  # Match original behavior of returning 1 on error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKHhfv2AacXq"
   },
   "source": [
    "#### **3.2.3. Age of Domain**\n",
    "\n",
    "This feature can be extracted from WHOIS database. Most phishing websites live for a short period of time. The minimum age of the legitimate domain is considered to be 12 months for this project. Age here is nothing but different between creation and expiration time.\n",
    "\n",
    "If age of domain > 12 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "li03hqJgH__j"
   },
   "outputs": [],
   "source": [
    "# 13.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbjRrzA7aenm"
   },
   "source": [
    "#### **3.2.4. End Period of Domain**\n",
    "\n",
    "This feature can be extracted from WHOIS database. For this feature, the remaining domain time is calculated by finding the different between expiration time & current time. The end period considered for the legitimate domain is 6 months or less  for this project. \n",
    "\n",
    "If end period of domain > 6 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NueO81-ttKYd"
   },
   "outputs": [],
   "source": [
    "# 14.End time of domain: The difference between termination time and current time (Domain_End) \n",
    "def domainEnd(domain_name):\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if isinstance(expiration_date,str):\n",
    "    try:\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if (expiration_date is None):\n",
    "      return 1\n",
    "  elif (type(expiration_date) is list):\n",
    "      return 1\n",
    "  else:\n",
    "    today = datetime.now()\n",
    "    end = abs((expiration_date - today).days)\n",
    "    if ((end/30) < 6):\n",
    "      end = 0\n",
    "    else:\n",
    "      end = 1\n",
    "  return end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oln3Xj-9t-Y6"
   },
   "source": [
    "## **3.3. HTML and JavaScript based Features**\n",
    "\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "\n",
    "*   IFrame Redirection\n",
    "*   Status Bar Customization\n",
    "*   Disabling Right Click\n",
    "*   Website Forwarding\n",
    "\n",
    "Each of these features are explained and the coded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lw0JmOGEQPwb"
   },
   "outputs": [],
   "source": [
    "# importing required packages for this section\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RES6bSWPy-Bj"
   },
   "source": [
    "### **3.3.1. IFrame Redirection**\n",
    "\n",
    "IFrame is an HTML tag used to display an additional webpage into one that is currently shown. Phishers can make use of the “iframe” tag and make it invisible i.e. without frame borders. In this regard, phishers make use of the “frameBorder” attribute which causes the browser to render a visual delineation. \n",
    "\n",
    "If the iframe is empty or repsonse is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2gpZEMSQGpu"
   },
   "outputs": [],
   "source": [
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "  if response == \"\":\n",
    "      return 1\n",
    "  else:\n",
    "      if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "          return 0\n",
    "      else:\n",
    "          return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ggh4ySE0BqjV"
   },
   "source": [
    "### **3.3.2. Status Bar Customization**\n",
    "\n",
    "Phishers may use JavaScript to show a fake URL in the status bar to users. To extract this feature, we must dig-out the webpage source code, particularly the “onMouseOver” event, and check if it makes any changes on the status bar\n",
    "\n",
    "If the response is empty or onmouseover is found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eapOq2afVGCF"
   },
   "outputs": [],
   "source": [
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response): \n",
    "  if response == \"\" :\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "      return 1\n",
    "    else:\n",
    "      return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IYgMTh1zBac9"
   },
   "source": [
    "### **3.3.3. Disabling Right Click**\n",
    "\n",
    "Phishers use JavaScript to disable the right-click function, so that users cannot view and save the webpage source code. This feature is treated exactly as “Using onMouseOver to hide the Link”. Nonetheless, for this feature, we will search for event “event.button==2” in the webpage source code and check if the right click is disabled.\n",
    "\n",
    "If the response is empty or onmouseover is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9x3lR3lFIVj2"
   },
   "outputs": [],
   "source": [
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "      return 0\n",
    "    else:\n",
    "      return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1NAnYm0wKKRC"
   },
   "source": [
    "### **3.3.4. Website Forwarding**\n",
    "The fine line that distinguishes phishing websites from legitimate ones is how many times a website has been redirected. In our dataset, we find that legitimate websites have been redirected one time max. On the other hand, phishing websites containing this feature have been redirected at least 4 times. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkpLyDIpKK0W"
   },
   "outputs": [],
   "source": [
    "# 18.Checks the number of forwardings (Web_Forwards)    \n",
    "def forwarding(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if len(response.history) <= 2:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVtp7WtjdIfv"
   },
   "source": [
    "## **4. Computing URL Features**\n",
    "\n",
    "Create a list and a function that calls the other functions and stores all the features of the URL in the list. We will extract the features of each URL and append to this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GzyvCg2rzWU"
   },
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def featureExtraction(url, label):\n",
    "    features = []\n",
    "    \n",
    "    # Address bar-based features (10)\n",
    "    features.append(getDomain(url))\n",
    "    features.append(havingIP(url))\n",
    "    features.append(haveAtSign(url))\n",
    "    features.append(getLength(url))\n",
    "    features.append(getDepth(url))\n",
    "    features.append(redirection(url))\n",
    "    features.append(httpDomain(url))\n",
    "    features.append(tinyURL(url))\n",
    "    features.append(prefixSuffix(url))\n",
    "    \n",
    "    # Domain-based features (4)\n",
    "    dns = 0\n",
    "    domain_name = None\n",
    "\n",
    "    try:\n",
    "        # Perform WHOIS lookup\n",
    "        domain_name = whois.whois(urlparse(url).netloc)\n",
    "    except Exception as e:\n",
    "        # Handle WHOIS lookup failure\n",
    "        dns = 1\n",
    "        print(f\"WHOIS lookup failed for URL: {url}, error: {e}\")\n",
    "\n",
    "    # Append DNS-based feature\n",
    "    features.append(dns)\n",
    "\n",
    "    # Append other domain-based features\n",
    "    # If WHOIS failed (dns = 1), provide fallback/default values\n",
    "    features.append(web_traffic(url))\n",
    "    features.append(1 if dns == 1 else domainAge(domain_name))\n",
    "    features.append(1 if dns == 1 else domainEnd(domain_name))\n",
    "    \n",
    "    # HTML & JavaScript-based features (4)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        response = \"\"\n",
    "        print(f\"Request failed for URL: {url}, error: {e}\")\n",
    "\n",
    "    features.append(iframe(response))\n",
    "    features.append(mouseOver(response))\n",
    "    features.append(rightClick(response))\n",
    "    features.append(forwarding(response))\n",
    "    \n",
    "    # Append label\n",
    "    features.append(label)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-v0QtVxld0Qq"
   },
   "source": [
    "### **4.1. Legitimate URLs:**\n",
    "\n",
    "Now, feature extraction is done on legitimate URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "s_2AX4OPeJRP",
    "outputId": "a4ac4615-e723-4969-d3c4-c7eab93515e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legiurl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.12/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKNg26HEP5kN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 19:53:16,651 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Name or service not known                                     | 0/5000 [00:00<?, ?it/s]\n",
      "Processing URLs:   0%|                                                                                                                                             | 1/5000 [00:04<6:22:27,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for URL: http://tobogo.net/cdsb/board.php?board=greet&bm=view&no=5716&category=&auth=&page=1&search=&keyword=&recom=, error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   0%|                                                                                                                                             | 3/5000 [00:05<2:15:23,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHOIS lookup failed for URL: http://couchtuner.eu.com/2013/05/anger-management-s2-e17-charlie-lets-kate-take-charge.html, error: No match for \"COUCHTUNER.EU.COM\".\n",
      ">>> Last update of whois database: 2025-01-27T14:23:06Z <<<\n",
      "\n",
      "NOTICE: The expiration date displayed in this record is the date the\n",
      "registrar's sponsorship of the domain name registration in the registry is\n",
      "currently set to expire. This date does not necessarily reflect the expiration\n",
      "date of the domain name registrant's agreement with the sponsoring\n",
      "registrar.  Users may consult the sponsoring registrar's Whois database to\n",
      "view the registrar's reported date of expiration for this registration.\n",
      "\n",
      "TERMS OF USE: You are not authorized to access or query our Whois\n",
      "database through the use of electronic processes that are high-volume and\n",
      "automated except as reasonably necessary to register domain names or\n",
      "modify existing registrations; the Data in VeriSign Global Registry\n",
      "Services' (\"VeriSign\") Whois database is provided by VeriSign for\n",
      "information purposes only, and to assist persons in obtaining information\n",
      "about or related to a domain name registration record. VeriSign does not\n",
      "guarantee its accuracy. By submitting a Whois query, you agree to abide\n",
      "by the following terms of use: You agree that you may use this Data only\n",
      "for lawful purposes and that under no circumstances will you use this Data\n",
      "to: (1) allow, enable, or otherwise support the transmission of mass\n",
      "unsolicited, commercial advertising or solicitations via e-mail, telephone,\n",
      "or facsimile; or (2) enable high volume, automated, electronic processes\n",
      "that apply to VeriSign (or its computer systems). The compilation,\n",
      "repackaging, dissemination or other use of this Data is expressly\n",
      "prohibited without the prior written consent of VeriSign. You agree not to\n",
      "use electronic processes that are automated and high-volume to access or\n",
      "query the Whois database except as reasonably necessary to register\n",
      "domain names or modify existing registrations. VeriSign reserves the right\n",
      "to restrict your access to the Whois database in its sole discretion to ensure\n",
      "operational stability.  VeriSign may restrict or terminate your access to the\n",
      "Whois database for failure to abide by these terms of use. VeriSign\n",
      "reserves the right to modify these terms at any time.\n",
      "\n",
      "The Registry database contains ONLY .COM, .NET, .EDU domains and\n",
      "Registrars.\n",
      "\n",
      "Request failed for URL: http://couchtuner.eu.com/2013/05/anger-management-s2-e17-charlie-lets-kate-take-charge.html, error: HTTPConnectionPool(host='couchtuner.eu.com', port=80): Max retries exceeded with url: /2013/05/anger-management-s2-e17-charlie-lets-kate-take-charge.html (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fa4b1a3dd90>: Failed to resolve 'couchtuner.eu.com' ([Errno -5] No address associated with hostname)\"))\n",
      "Request failed for URL: http://olx.in/hi/item/nokia-5800-express-music-perfect-working-condition-body-average-cond-IDTIzUp.html, error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "WHOIS lookup failed for URL: http://icicibank.com/Personal-Banking/offers/offer-detail.page?id=offer-ezeego-domestic-airtravel-20141407112611060, error: timed out\n",
      "WHOIS lookup failed for URL: http://nypost.com/2015/05/07/us-indifference-leaves-saudis-partnering-with-terrorists/, error: timed out\n",
      "WHOIS lookup failed for URL: http://extratorrent.cc/torrent/4190536/AOMEI+Backupper+Technician+%2B+Server+Edition+2.8.0+%2B+Patch+%2B+Key+%2B+100%25+Working.html, error: timed out\n",
      "WHOIS lookup failed for URL: http://tunein.com/radio/Carolina-Mudcats-at-Myrtle-Beach-Pelicans-May-13-2015-p729095/15480783/ca-pub-1542925551861702/ProgramTopBanner, error: timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 19:53:25,363 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Name or service not known                           | 4/5000 [00:11<4:19:45,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for URL: http://extratorrent.cc/torrent/4190536/AOMEI+Backupper+Technician+%2B+Server+Edition+2.8.0+%2B+Patch+%2B+Key+%2B+100%25+Working.html, error: HTTPConnectionPool(host='extratorrent.cc', port=80): Max retries exceeded with url: /torrent/4190536/AOMEI+Backupper+Technician+%2B+Server+Edition+2.8.0+%2B+Patch+%2B+Key+%2B+100%25+Working.html (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fa4b1a3da00>: Failed to resolve 'extratorrent.cc' ([Errno -5] No address associated with hostname)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   0%|▎                                                                                                                                           | 11/5000 [00:13<1:12:22,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for URL: http://indianexpress.com/article/world/asia/pak-officer-gave-up-osama-kayani-isi-chief-helped-us/, error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   0%|▋                                                                                                                                             | 24/5000 [00:17<40:55,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for URL: http://emgn.com/tv/schnauzer-passes-out-with-excitement-when-he-is-reunited-with-his-human-after-2-years/, error: HTTPConnectionPool(host='emgn.com', port=80): Max retries exceeded with url: /tv/schnauzer-passes-out-with-excitement-when-he-is-reunited-with-his-human-after-2-years/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fa4bcb09430>: Failed to resolve 'emgn.com' ([Errno -3] Temporary failure in name resolution)\"))\n",
      "Request failed for URL: http://spankbang.com/4ze1/video/brunette+with+big+boobs+fucked+in+a+cellar+public+agent, error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "Request failed for URL: http://emgn.com/movies/person-of-interest-what-to-expect-from-season-4-release-date/, error: HTTPConnectionPool(host='emgn.com', port=80): Max retries exceeded with url: /movies/person-of-interest-what-to-expect-from-season-4-release-date/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fa4b1a3d1f0>: Failed to resolve 'emgn.com' ([Errno -3] Temporary failure in name resolution)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 19:53:36,201 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Name or service not known\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for URL: http://extratorrent.cc/torrent/4190380/VA-Unusual_Techno_One_LP-WEB-2015-CBR_INT.html, error: HTTPConnectionPool(host='extratorrent.cc', port=80): Max retries exceeded with url: /torrent/4190380/VA-Unusual_Techno_One_LP-WEB-2015-CBR_INT.html (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fa4bcb0bad0>: Failed to resolve 'extratorrent.cc' ([Errno -5] No address associated with hostname)\"))\n",
      "Request failed for URL: http://mylust.com/videos/235751/sexy-hentai-chick-gets-her-huge-succulent-tits-squeezed/, error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 19:53:46,941 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Name or service not known\n",
      "2025-01-27 19:53:52,132 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Name or service not known\n",
      "2025-01-27 19:53:52,504 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
      "2025-01-27 19:53:54,857 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Name or service not known\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for URL: http://persianblog.ir/tags/42604/8/%d8%b3%d9%87%d8%b1%d8%a7%d8%a8_%d8%b3%d9%be%d9%87%d8%b1%db%8c/, error: HTTPConnectionPool(host='persianblog.ir', port=80): Max retries exceeded with url: /tags/42604/8/%D8%B3%D9%87%D8%B1%D8%A7%D8%A8_%D8%B3%D9%BE%D9%87%D8%B1%DB%8C/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fa4b1a12a20>: Failed to resolve 'persianblog.ir' ([Errno -3] Temporary failure in name resolution)\"))\n"
     ]
    }
   ],
   "source": [
    "label = 0  # Define the label variable\n",
    "urls = [(legiurl['URLs'][i], label) for i in range(5000)]  # Ensure label is accessible\n",
    "legi_features = []\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_url(url_label):\n",
    "    url, label = url_label\n",
    "    return featureExtraction(url, label)\n",
    "\n",
    "# Using ThreadPoolExecutor for parallel processing\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for features in tqdm(executor.map(process_url, urls), total=len(urls), desc=\"Processing URLs\"):\n",
    "        legi_features.append(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "DSuxYREMi0fr",
    "outputId": "de1e393b-ed2b-4021-a05b-d5b696852365"
   },
   "outputs": [],
   "source": [
    "#converting the list to dataframe\n",
    "feature_names = ['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth','Redirection', \n",
    "                      'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', \n",
    "                      'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over','Right_Click', 'Web_Forwards', 'Label']\n",
    "\n",
    "legitimate = pd.DataFrame(legi_features, columns= feature_names)\n",
    "legitimate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jVcLHvXC031"
   },
   "outputs": [],
   "source": [
    "# Storing the extracted legitimate URLs fatures to csv file\n",
    "legitimate.to_csv('legitimate.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrZJo_aboeGb"
   },
   "source": [
    "### **4.2. Phishing URLs:**\n",
    "\n",
    "Now, feature extraction is performed on phishing URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PSKf1PCeoeGd",
    "outputId": "953c12ff-7f25-4491-ce67-ffcf4b1251b0"
   },
   "outputs": [],
   "source": [
    "phishurl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGhZMkbaoeGh"
   },
   "outputs": [],
   "source": [
    "#Extracting the feautres & storing them in a list\n",
    "phish_features = []\n",
    "label = 1\n",
    "for i in range(0, 5000):\n",
    "  url = phishurl['url'][i]\n",
    "  phish_features.append(featureExtraction(url,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "1brvc6kmoeGk",
    "outputId": "58a2e2cd-886f-414a-e2c6-2e5b7894efdd"
   },
   "outputs": [],
   "source": [
    "#converting the list to dataframe\n",
    "feature_names = ['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth','Redirection', \n",
    "                      'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', \n",
    "                      'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over','Right_Click', 'Web_Forwards', 'Label']\n",
    "\n",
    "phishing = pd.DataFrame(phish_features, columns= feature_names)\n",
    "phishing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhBbG2O7E30d"
   },
   "outputs": [],
   "source": [
    "# Storing the extracted legitimate URLs fatures to csv file\n",
    "phishing.to_csv('phishing.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB43ozsPq-6c"
   },
   "source": [
    "## **5. Final Dataset**\n",
    "\n",
    "In the above section we formed two dataframes of legitimate & phishing URL features. Now, we will combine them to a single dataframe and export the data to csv file for the Machine Learning training done in other notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "ktJNvDY5sUsX",
    "outputId": "b64aa1a8-59a1-44a9-92d4-fc9cd811521b"
   },
   "outputs": [],
   "source": [
    "#Concatenating the dataframes into one \n",
    "urldata = pd.concat([legitimate, phishing]).reset_index(drop=True)\n",
    "urldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "u1Viw3jKh3_o",
    "outputId": "eb924dbb-e26a-4711-a46a-3e39b4a37718"
   },
   "outputs": [],
   "source": [
    "urldata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1NNxgbVCr7vt",
    "outputId": "3064082c-4508-4579-8128-bff9842a04b7"
   },
   "outputs": [],
   "source": [
    "urldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "596496VUrhRI"
   },
   "outputs": [],
   "source": [
    "# Storing the data in CSV file\n",
    "urldata.to_csv('urldata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srm3VLlHrmFN"
   },
   "source": [
    "## **6. Conclusion**\n",
    "\n",
    "With this the objective of this notebook is achieved. We finally extracted 18 features for 10,000 URL which has 5000 phishing & 5000 legitimate URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybur8dewifEw"
   },
   "source": [
    "## **7. References**\n",
    "\n",
    "* https://archive.ics.uci.edu/ml/datasets/Phishing+Websites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "URL Feature Extraction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
